### rl and transformers
အရင်ကတော့ rl နဲ့ transformer သိပ်မသက်ဆိုင်ပေမဲ့ ယနေ့ခေတ်မှာတော့ အောက်ပါ ၃ချက်ကြောင့် rl နဲ့ nlp မှာသုံးတဲ့ transfromer ကို ဆက်စပ်သုံးစွဲလာကြပါတယ်။

- ၁။ Decision Transformer: RL ကို Sequence Modeling အဖြစ် ပြောင်းလဲခြင်း
ပုံမှန် RL က "အခြေအနေတစ်ခုမှာ ဘယ်လိုလုပ်ဆောင်ချက် (Action) လုပ်ရင် ကောင်းမလဲ" ဆိုတာကို Trial and Error နဲ့ သင်ယူတာပါ။ ဒါပေမဲ့ Transformer ရဲ့ စွမ်းဆောင်ရည်ကို သုံးပြီး Decision Transformer ဆိုတာ ပေါ်လာပါတယ်။

    - သူက RL ပြဿနာကို ဘာသာစကားတစ်ခုလိုမျိုး Sequence တစ်ခုအနေနဲ့ မြင်လိုက်တာပါ။

    - \"အခြေအနေ (State) -> လုပ်ဆောင်ချက် (Action) -> ရလဒ် (Reward)\" ဆိုတဲ့ အစီအစဉ်တွေကို Transformer ထဲ ထည့်ပြီး အကောင်းဆုံးရလဒ်ရအောင် ဘာလုပ်ရမလဲဆိုတာကို ခန့်မှန်းခိုင်းတာ ဖြစ်ပါတယ်။

- ၂။ RLHF (Reinforcement Learning from Human Feedback)
ဒါကတော့ ကျွန်တော်တို့ အသုံးများတဲ့ ChatGPT လိုမျိုး LLM (Large Language Models) တွေမှာ သုံးတဲ့ နည်းပညာပါ။

    - Transformers: ChatGPT ရဲ့ အခြေခံ Foundation က Transformer architecture ဖြစ်ပါတယ်။ သူက စာတွေကို ကောင်းကောင်း ရေးတတ်အောင် သင်ထားပေးတယ်။

    - RL: Transformer က ထွက်လာတဲ့ အဖြေကို လူသားတွေက "ဒါကောင်းတယ်၊ ဒါမကောင်းဘူး" လို့ အမှတ်ပေး (Reward ပေး) ပြီး RL နည်းနဲ့ ထပ်မံ စည်းကမ်းသတ်မှတ် (Fine-tune) တာ ဖြစ်ပါတယ်။

- ၃။ Long-range Dependencies (အရှည်ကြီး မှတ်မိနိုင်စွမ်း)
RL မှာ အရင်ကသုံးတဲ့ RNN ဒါမှမဟုတ် LSTM တွေက အတိတ်က အဖြစ်အပျက် အကြာကြီးကို မမှတ်မိနိုင်ကြပါဘူး။ Transformer မှာပါတဲ့ Attention Mechanism ကြောင့် RL Agent တစ်ခုဟာ လွန်ခဲ့တဲ့ အဆင့်ပေါင်းများစွာက အဖြစ်အပျက်တွေကို ပြန်ကြည့်ပြီး အခုလက်ရှိမှာ ပိုကောင်းတဲ့ ဆုံးဖြတ်ချက်တွေ ချနိုင်လာပါတယ်။
